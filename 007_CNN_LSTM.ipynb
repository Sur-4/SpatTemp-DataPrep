{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade pip\n",
    "# !pip install -q tensorflow tensorflow-metal scikit-learn ipywidgets\n",
    "# !pip install -q scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size_pixels = 64\n",
    "model_input_width = 6  # number of images before the event\n",
    "buffer_size = 100\n",
    "# num_classes = 6\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "datasets_folder = os.path.join(\"E:\\\\Workspace\\\\Thesis_dataset\", \"illinois_dataset\")\n",
    "# dataset_folder_name = \"Quercus_germany_200_stations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test_data.npz\n",
      "E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test.csv\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_folder_path = datasets_folder\n",
    "os.makedirs(dataset_folder_path, exist_ok=True)\n",
    "\n",
    "record_id_column_name = 'record_id'\n",
    "label_column_name = \"ordered_phase_id\"\n",
    "\n",
    "train_timeseries_file_path = os.path.join(dataset_folder_path, \"test_data.npz\")\n",
    "print(train_timeseries_file_path)\n",
    "train_label_file_path = os.path.join(dataset_folder_path, \"test.csv\")\n",
    "print(train_label_file_path)\n",
    "print(\"-\" * 60)\n",
    "# val_timeseries_file_path = os.path.join(dataset_folder_path, \"val_data.npz\")\n",
    "# print(val_timeseries_file_path)\n",
    "# val_label_file_path = os.path.join(dataset_folder_path, \"val.csv\")\n",
    "# print(val_label_file_path)\n",
    "# print(\"-\" * 60)\n",
    "# test_timeseries_file_path = os.path.join(dataset_folder_path, \"test_data.npz\")\n",
    "# print(test_timeseries_file_path)\n",
    "# test_label_file_path = os.path.join(dataset_folder_path, \"test.csv\")\n",
    "# print(test_label_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 64, 64, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_file = np.load(train_timeseries_file_path, mmap_mode=\"r\")\n",
    "first_array_key = next(iter(npz_file))\n",
    "timeseries_shape = npz_file[first_array_key].shape\n",
    "timeseries_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train, validation, and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train.csv\"\n",
    "test_label_file_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test.csv\"\n",
    "record_id_column_name = \"id\"\n",
    "label_column_name = \"val_yield\"\n",
    "timeseries_npz_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train_data.npz\"\n",
    "test_timeseries_file_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train_data.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    label_csv_path, record_id_column_name, label_column_name, timeseries_npz_path\n",
    "):\n",
    "\n",
    "    # Check if the inputs are a byte string and decode it to a regular string if necessary\n",
    "    if isinstance(label_csv_path, bytes):\n",
    "        label_csv_path = label_csv_path.decode(\"utf-8\")\n",
    "    if isinstance(timeseries_npz_path, bytes):\n",
    "        timeseries_npz_path = timeseries_npz_path.decode(\"utf-8\")\n",
    "    if isinstance(record_id_column_name, bytes):\n",
    "        record_id_column_name = record_id_column_name.decode(\"utf-8\")\n",
    "    if isinstance(label_column_name, bytes):\n",
    "        label_column_name = label_column_name.decode(\"utf-8\")\n",
    "\n",
    "    # Load the labels CSV\n",
    "    labels_df = pd.read_csv(label_csv_path)\n",
    "\n",
    "    # Load the npz file\n",
    "    with np.load(timeseries_npz_path, allow_pickle=True) as npz_file:\n",
    "        for _, row in labels_df.iterrows():\n",
    "            record_id = str(\n",
    "                row[record_id_column_name]\n",
    "            )  # Ensure record_id is treated as a string\n",
    "            target = row[label_column_name]\n",
    "            if record_id in npz_file.files:\n",
    "                # Extract the time series data using record_id\n",
    "                time_series = npz_file[record_id]\n",
    "                # print(record_id, target)\n",
    "                yield time_series, target\n",
    "\n",
    "\n",
    "# Determine the output types\n",
    "output_types = (tf.float32, tf.int64)\n",
    "\n",
    "# Determine the output shapes\n",
    "output_shapes = (timeseries_shape, ())  #  ((6, 11, 64, 64), ())\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,  # Generator function\n",
    "    args=(\n",
    "        train_label_file_path,\n",
    "        record_id_column_name,\n",
    "        label_column_name,\n",
    "        train_timeseries_file_path,\n",
    "    ),  # Arguments to pass to the generator\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes,\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=buffer_size)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# # Create validation dataset\n",
    "# val_dataset = tf.data.Dataset.from_generator(\n",
    "#     data_generator,  # Generator function\n",
    "#     args=(\n",
    "#         val_label_file_path,\n",
    "#         record_id_column_name,\n",
    "#         label_column_name,\n",
    "#         val_timeseries_file_path,\n",
    "#     ),  # Arguments to pass to the generator\n",
    "#     output_types=output_types,\n",
    "#     output_shapes=output_shapes,\n",
    "# )\n",
    "# val_dataset = (\n",
    "#     # val_dataset.shuffle(buffer_size=buffer_size)\n",
    "#     val_dataset.batch(batch_size)\n",
    "#     .prefetch(tf.data.AUTOTUNE)\n",
    "# )\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,  # Generator function\n",
    "    args=(\n",
    "        test_label_file_path,\n",
    "        record_id_column_name,\n",
    "        label_column_name,\n",
    "        test_timeseries_file_path,\n",
    "    ),  # Arguments to pass to the generator\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes,\n",
    ")\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shape of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train Dataset ---\n",
      "Shape of data: (8, 6, 64, 64, 15)\n",
      "Shape of label: (8,)\n",
      "--- Test Dataset ---\n",
      "Shape of data: (8, 6, 64, 64, 15)\n",
      "Shape of label: (8,)\n"
     ]
    }
   ],
   "source": [
    "# Function to print the shapes of the dataset\n",
    "def print_dataset_shapes(dataset, dataset_name=\"Dataset\"):\n",
    "    print(f\"--- {dataset_name} ---\")\n",
    "    for data, label in dataset.take(1):  # Take a single batch from the dataset\n",
    "        print(f\"Shape of data: {data.shape}\")\n",
    "        print(f\"Shape of label: {label.shape}\")\n",
    "\n",
    "# Print shapes for train, validation, and test datasets\n",
    "print_dataset_shapes(train_dataset, \"Train Dataset\")\n",
    "# print_dataset_shapes(val_dataset, \"Validation Dataset\")\n",
    "print_dataset_shapes(test_dataset, \"Test Dataset\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apply_interpolation_to_band' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[205], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply interpolation for band 13 on the train dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mapply_interpolation_to_band\u001b[49m(train_dataset, band_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[0;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m apply_interpolation_to_band(val_dataset, band_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n\u001b[0;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m apply_interpolation_to_band(test_dataset, band_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'apply_interpolation_to_band' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply interpolation for band 13 on the train dataset\n",
    "train_dataset = apply_interpolation_to_band(train_dataset, band_num=13)\n",
    "val_dataset = apply_interpolation_to_band(val_dataset, band_num=13)\n",
    "test_dataset = apply_interpolation_to_band(test_dataset, band_num=13)\n",
    "\n",
    "# Apply interpolation for band 14 on the train dataset\n",
    "train_dataset = apply_interpolation_to_band(train_dataset, band_num=14)\n",
    "val_dataset = apply_interpolation_to_band(val_dataset, band_num=14)\n",
    "test_dataset = apply_interpolation_to_band(test_dataset, band_num=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalization_stats(dataset):\n",
    "    \"\"\"\n",
    "    Compute the mean and standard deviation of the dataset.\n",
    "    \n",
    "    Args:\n",
    "    dataset: A TensorFlow Dataset from which the statistics should be computed.\n",
    "\n",
    "    Returns:\n",
    "    mean: Mean of the dataset.\n",
    "    stddev: Standard deviation of the dataset.\n",
    "    \"\"\"\n",
    "    # Initialize variables to compute mean and variance\n",
    "    total_sum = 0\n",
    "    total_squared_sum = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # Iterate through the dataset to compute the sum and squared sum\n",
    "    for data, _ in dataset:\n",
    "        total_sum += tf.reduce_sum(data, axis=0)\n",
    "        total_squared_sum += tf.reduce_sum(tf.square(data), axis=0)\n",
    "        total_count += tf.cast(tf.shape(data)[0], tf.float32)\n",
    "\n",
    "    # Compute the mean and variance\n",
    "    mean = total_sum / total_count\n",
    "    variance = (total_squared_sum / total_count) - tf.square(mean)\n",
    "    stddev = tf.sqrt(variance)\n",
    "    \n",
    "    return mean, stddev\n",
    "\n",
    "def normalize_dataset(dataset, mean, stddev):\n",
    "    \"\"\"\n",
    "    Normalize the dataset using mean and standard deviation, replacing NaN values with the mean.\n",
    "\n",
    "    Args:\n",
    "    dataset: A TensorFlow Dataset that needs to be normalized.\n",
    "    mean: The mean values for each feature.\n",
    "    stddev: The standard deviation for each feature.\n",
    "\n",
    "    Returns:\n",
    "    A normalized TensorFlow Dataset.\n",
    "    \"\"\"\n",
    "    # Function to replace NaN values with the mean and normalize\n",
    "    def replace_nan_and_normalize(data, target):\n",
    "        # Replace NaN values with the mean\n",
    "        data_no_nan = tf.where(tf.math.is_nan(data), mean, data)\n",
    "        # Apply normalization using broadcasting\n",
    "        normalized_data = (data_no_nan - mean) / stddev\n",
    "        return normalized_data, target\n",
    "\n",
    "    # Apply the replace and normalization function\n",
    "    return dataset.map(replace_nan_and_normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_dataset is a tf.data.Dataset object\n",
    "mean, stddev = compute_normalization_stats(train_dataset)\n",
    "\n",
    "# Normalize the train dataset\n",
    "train_dataset = normalize_dataset(train_dataset, mean, stddev)\n",
    "\n",
    "# Normalize the validation dataset\n",
    "# ''val_dataset = normalize_dataset(val_dataset, mean, stddev)\n",
    "''\n",
    "# Normalize the test dataset\n",
    "test_dataset = normalize_dataset(test_dataset, mean, stddev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First Record from Train Dataset ---\n",
      "Data: [[[[-0.83323246 -0.4531153  -0.4134176  ...         nan  0.9348566\n",
      "     0.81256604]\n",
      "   [-0.83323246 -0.46487066 -0.4436577  ...         nan  0.9350435\n",
      "     0.8125327 ]\n",
      "   [-0.780351   -0.47659656 -0.46685538 ...         nan  0.93527263\n",
      "     0.8124918 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.6231799  -0.6443652  ...         nan  0.9338001\n",
      "     0.8051857 ]\n",
      "   [-0.54009897 -0.6119555  -0.6391573  ...         nan  0.9333845\n",
      "     0.8051065 ]\n",
      "   [-0.54009897 -0.6020085  -0.631915   ...         nan  0.93308604\n",
      "     0.80504197]]\n",
      "\n",
      "  [[-0.83323246 -0.45687667 -0.42399523 ...         nan  0.93467456\n",
      "     0.8126163 ]\n",
      "   [-0.83323246 -0.4635476  -0.4428054  ...         nan  0.93487054\n",
      "     0.8125837 ]\n",
      "   [-0.780351   -0.4704841  -0.45715842 ...         nan  0.93511486\n",
      "     0.81254345]\n",
      "   ...\n",
      "   [-0.4953167  -0.6285186  -0.64732325 ...         nan  0.93441504\n",
      "     0.8052496 ]\n",
      "   [-0.54009897 -0.6184831  -0.64215744 ...         nan  0.9339787\n",
      "     0.80517006]\n",
      "   [-0.54009897 -0.6077093  -0.63533133 ...         nan  0.933654\n",
      "     0.8051048 ]]\n",
      "\n",
      "  [[-0.83323246 -0.46223566 -0.44151556 ...         nan  0.9343657\n",
      "     0.812707  ]\n",
      "   [-0.83323246 -0.459993   -0.4408542  ...         nan  0.93457663\n",
      "     0.8126754 ]\n",
      "   [-0.780351   -0.45918837 -0.4390851  ...         nan  0.9348467\n",
      "     0.81263644]\n",
      "   ...\n",
      "   [-0.4953167  -0.6356795  -0.6502632  ...         nan  0.9354676\n",
      "     0.8053656 ]\n",
      "   [-0.54009897 -0.6277557  -0.64533556 ...         nan  0.9349958\n",
      "     0.80528563]\n",
      "   [-0.54009897 -0.6159207  -0.6387288  ...         nan  0.9346258\n",
      "     0.8052189 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.59925973 -0.6061641  ...         nan  0.9337263\n",
      "     0.7903684 ]\n",
      "   [-0.5541568  -0.58779806 -0.5736151  ...         nan  0.93470573\n",
      "     0.79027194]\n",
      "   [-0.54009897 -0.5769305  -0.54538774 ...         nan  0.93597335\n",
      "     0.7901612 ]\n",
      "   ...\n",
      "   [-0.66202563 -0.54558355 -0.5323208  ...         nan  0.9880682\n",
      "     0.7827292 ]\n",
      "   [-0.7118441  -0.5246956  -0.5043714  ...         nan  0.98812383\n",
      "     0.78268987]\n",
      "   [-0.7118441  -0.5081602  -0.48166776 ...         nan  0.98816544\n",
      "     0.7826551 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.9337263\n",
      "     0.7903684 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.93470573\n",
      "     0.79027194]\n",
      "   [-0.54009897         nan         nan ...         nan  0.93597335\n",
      "     0.7901612 ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.9880682\n",
      "     0.7827292 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.98812383\n",
      "     0.78268987]\n",
      "   [-0.7118441          nan         nan ...         nan  0.98816544\n",
      "     0.7826551 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.9337263\n",
      "     0.7903684 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.93470573\n",
      "     0.79027194]\n",
      "   [-0.54009897         nan         nan ...         nan  0.93597335\n",
      "     0.7901612 ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.9880682\n",
      "     0.7827292 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.98812383\n",
      "     0.78268987]\n",
      "   [-0.7118441          nan         nan ...         nan  0.98816544\n",
      "     0.7826551 ]]]\n",
      "\n",
      "\n",
      " [[[-0.83323246 -0.37135106 -0.34829965 ...         nan  0.93465066\n",
      "    -0.45201087]\n",
      "   [-0.83323246 -0.37322086 -0.35995564 ...         nan  0.9347302\n",
      "    -0.45200834]\n",
      "   [-0.780351   -0.37783477 -0.36802468 ...         nan  0.9348302\n",
      "    -0.45200533]\n",
      "   ...\n",
      "   [-0.4953167  -0.49432787 -0.4987351  ...         nan  0.9350195\n",
      "    -0.4519089 ]\n",
      "   [-0.54009897 -0.50137997 -0.49719948 ...         nan  0.9347536\n",
      "    -0.45190808]\n",
      "   [-0.54009897 -0.5060525  -0.49493524 ...         nan  0.9344545\n",
      "    -0.4519072 ]]\n",
      "\n",
      "  [[-0.83323246 -0.3813714  -0.3661136  ...         nan  0.9346303\n",
      "    -0.4520085 ]\n",
      "   [-0.83323246 -0.380221   -0.3702382  ...         nan  0.9347059\n",
      "    -0.45200607]\n",
      "   [-0.780351   -0.3810636  -0.37173375 ...         nan  0.9348032\n",
      "    -0.45200318]\n",
      "   ...\n",
      "   [-0.4953167  -0.4929664  -0.4995343  ...         nan  0.9350055\n",
      "    -0.45190722]\n",
      "   [-0.54009897 -0.49892727 -0.4992683  ...         nan  0.93472886\n",
      "    -0.45190638]\n",
      "   [-0.54009897 -0.503207   -0.49833724 ...         nan  0.93441886\n",
      "    -0.45190555]]\n",
      "\n",
      "  [[-0.83323246 -0.39321527 -0.38960433 ...         nan  0.93459624\n",
      "    -0.45200467]\n",
      "   [-0.83323246 -0.3880083  -0.38299358 ...         nan  0.93466496\n",
      "    -0.45200244]\n",
      "   [-0.780351   -0.38302654 -0.37380186 ...         nan  0.93475735\n",
      "    -0.4519996 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.4902416  -0.49997285 ...         nan  0.93497723\n",
      "    -0.4519043 ]\n",
      "   [-0.54009897 -0.4945138  -0.50185853 ...         nan  0.93468195\n",
      "    -0.45190343]\n",
      "   [-0.54009897 -0.49771634 -0.5038935  ...         nan  0.9343537\n",
      "    -0.4519027 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.46732226 -0.44619632 ...         nan  0.93167067\n",
      "    -0.451479  ]\n",
      "   [-0.5541568  -0.48212937 -0.45063633 ...         nan  0.93172187\n",
      "    -0.45147547]\n",
      "   [-0.54009897 -0.49036938 -0.45632315 ...         nan  0.93179154\n",
      "    -0.45147088]\n",
      "   ...\n",
      "   [-0.66202563 -0.6450335  -0.66173446 ...         nan  0.9323145\n",
      "    -0.45145294]\n",
      "   [-0.7118441  -0.639829   -0.65696394 ...         nan  0.9322585\n",
      "    -0.45145565]\n",
      "   [-0.7118441  -0.6319149  -0.64922786 ...         nan  0.93221074\n",
      "    -0.4514577 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.93167067\n",
      "    -0.451479  ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.93172187\n",
      "    -0.45147547]\n",
      "   [-0.54009897         nan         nan ...         nan  0.93179154\n",
      "    -0.45147088]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.9323145\n",
      "    -0.45145294]\n",
      "   [-0.7118441          nan         nan ...         nan  0.9322585\n",
      "    -0.45145565]\n",
      "   [-0.7118441          nan         nan ...         nan  0.93221074\n",
      "    -0.4514577 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.93167067\n",
      "    -0.451479  ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.93172187\n",
      "    -0.45147547]\n",
      "   [-0.54009897         nan         nan ...         nan  0.93179154\n",
      "    -0.45147088]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.9323145\n",
      "    -0.45145294]\n",
      "   [-0.7118441          nan         nan ...         nan  0.9322585\n",
      "    -0.45145565]\n",
      "   [-0.7118441          nan         nan ...         nan  0.93221074\n",
      "    -0.4514577 ]]]\n",
      "\n",
      "\n",
      " [[[-0.83323246 -0.37238002 -0.2451186  ...         nan  0.69607526\n",
      "     0.85991085]\n",
      "   [-0.83323246 -0.43108776 -0.32470617 ...         nan  0.69611406\n",
      "     0.85979784]\n",
      "   [-0.780351   -0.48504072 -0.39228287 ...         nan  0.69616234\n",
      "     0.859652  ]\n",
      "   ...\n",
      "   [-0.4953167  -0.4477332  -0.4666614  ...         nan  0.6844055\n",
      "     0.8559345 ]\n",
      "   [-0.54009897 -0.44055614 -0.465172   ...         nan  0.68392503\n",
      "     0.85597646]\n",
      "   [-0.54009897 -0.43919155 -0.4618985  ...         nan  0.6835366\n",
      "     0.85600543]]\n",
      "\n",
      "  [[-0.83323246 -0.38673902 -0.26659018 ...         nan  0.6961694\n",
      "     0.8599471 ]\n",
      "   [-0.83323246 -0.42710185 -0.31916663 ...         nan  0.69621545\n",
      "     0.8598335 ]\n",
      "   [-0.780351   -0.4651257  -0.36391702 ...         nan  0.6962733\n",
      "     0.8596854 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.4481921  -0.4667556  ...         nan  0.6847773\n",
      "     0.85571736]\n",
      "   [-0.54009897 -0.44141066 -0.46361646 ...         nan  0.684294\n",
      "     0.85576326]\n",
      "   [-0.54009897 -0.4384953  -0.46001974 ...         nan  0.68391365\n",
      "     0.85579574]]\n",
      "\n",
      "  [[-0.83323246 -0.4041815  -0.29358792 ...         nan  0.69633085\n",
      "     0.8600158 ]\n",
      "   [-0.83323246 -0.41402355 -0.30007306 ...         nan  0.69638896\n",
      "     0.85990006]\n",
      "   [-0.780351   -0.4247318  -0.30925536 ...         nan  0.6964631\n",
      "     0.8597494 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.44852528 -0.46378675 ...         nan  0.68541384\n",
      "     0.8553496 ]\n",
      "   [-0.54009897 -0.44286597 -0.45931968 ...         nan  0.68492585\n",
      "     0.85540265]\n",
      "   [-0.54009897 -0.43738356 -0.4547844  ...         nan  0.68455917\n",
      "     0.85544133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.40901452 -0.36599267 ...         nan  0.67661524\n",
      "     0.8679347 ]\n",
      "   [-0.5541568  -0.42235184 -0.34524342 ...         nan  0.67760426\n",
      "     0.86806226]\n",
      "   [-0.54009897 -0.43850654 -0.32514945 ...         nan  0.6788928\n",
      "     0.8682269 ]\n",
      "   ...\n",
      "   [-0.66202563 -0.33925167 -0.29184243 ...         nan  0.7417118\n",
      "     0.88127226]\n",
      "   [-0.7118441  -0.30815443 -0.23609376 ...         nan  0.7423905\n",
      "     0.8811626 ]\n",
      "   [-0.7118441  -0.28513762 -0.19801465 ...         nan  0.7429082\n",
      "     0.88108075]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.67661524\n",
      "     0.8679347 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.67760426\n",
      "     0.86806226]\n",
      "   [-0.54009897         nan         nan ...         nan  0.6788928\n",
      "     0.8682269 ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.7417118\n",
      "     0.88127226]\n",
      "   [-0.7118441          nan         nan ...         nan  0.7423905\n",
      "     0.8811626 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.7429082\n",
      "     0.88108075]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.67661524\n",
      "     0.8679347 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.67760426\n",
      "     0.86806226]\n",
      "   [-0.54009897         nan         nan ...         nan  0.6788928\n",
      "     0.8682269 ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.7417118\n",
      "     0.88127226]\n",
      "   [-0.7118441          nan         nan ...         nan  0.7423905\n",
      "     0.8811626 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.7429082\n",
      "     0.88108075]]]\n",
      "\n",
      "\n",
      " [[[-0.83323246 -0.04262753 -0.02414188 ...         nan  0.7189226\n",
      "     0.59696954]\n",
      "   [-0.83323246 -0.14824474 -0.16134053 ...         nan  0.71769464\n",
      "     0.59714174]\n",
      "   [-0.780351   -0.25075924 -0.2874996  ...         nan  0.7161355\n",
      "     0.5973603 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.6590288  -0.6700034  ...         nan  0.68211275\n",
      "     0.59677505]\n",
      "   [-0.54009897 -0.6540202  -0.668743   ...         nan  0.68210703\n",
      "     0.59641707]\n",
      "   [-0.54009897 -0.6476475  -0.6654488  ...         nan  0.68210655\n",
      "     0.596145  ]]\n",
      "\n",
      "  [[-0.83323246 -0.11637105 -0.0944814  ...         nan  0.71843714\n",
      "     0.59703803]\n",
      "   [-0.83323246 -0.1748211  -0.18271963 ...         nan  0.7171562\n",
      "     0.59721094]\n",
      "   [-0.780351   -0.23739517 -0.27272448 ...         nan  0.7155326\n",
      "     0.5974293 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.65701735 -0.6680709  ...         nan  0.6808833\n",
      "     0.59690857]\n",
      "   [-0.54009897 -0.6521875  -0.6662757  ...         nan  0.6808482\n",
      "     0.596544  ]\n",
      "   [-0.54009897 -0.6459867  -0.66258353 ...         nan  0.6808571\n",
      "     0.59626603]]\n",
      "\n",
      "  [[-0.83323246 -0.24160357 -0.21527158 ...         nan  0.71760184\n",
      "     0.5971574 ]\n",
      "   [-0.83323246 -0.2199248  -0.219374   ...         nan  0.71622974\n",
      "     0.5973314 ]\n",
      "   [-0.780351   -0.21493474 -0.24720334 ...         nan  0.71449614\n",
      "     0.59754956]\n",
      "   ...\n",
      "   [-0.4953167  -0.6534694  -0.6631405  ...         nan  0.6787802\n",
      "     0.59713715]\n",
      "   [-0.54009897 -0.64812297 -0.6601402  ...         nan  0.67869496\n",
      "     0.59676135]\n",
      "   [-0.54009897 -0.64244676 -0.65680116 ...         nan  0.6787201\n",
      "     0.5964734 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.09813622 -0.12904245 ...         nan  0.732179\n",
      "     0.61328524]\n",
      "   [-0.5541568  -0.07608083 -0.10768796 ...         nan  0.7321278\n",
      "     0.6133182 ]\n",
      "   [-0.54009897 -0.05063094 -0.08536796 ...         nan  0.7320574\n",
      "     0.61336035]\n",
      "   ...\n",
      "   [-0.66202563  1.3185018   1.355957   ...         nan  0.7152345\n",
      "     0.6016311 ]\n",
      "   [-0.7118441   1.4764825   1.5406251  ...         nan  0.714475\n",
      "     0.60104716]\n",
      "   [-0.7118441   1.6319093   1.7193303  ...         nan  0.71389043\n",
      "     0.6005955 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.732179\n",
      "     0.61328524]\n",
      "   [-0.5541568          nan         nan ...         nan  0.7321278\n",
      "     0.6133182 ]\n",
      "   [-0.54009897         nan         nan ...         nan  0.7320574\n",
      "     0.61336035]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.7152345\n",
      "     0.6016311 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.714475\n",
      "     0.60104716]\n",
      "   [-0.7118441          nan         nan ...         nan  0.71389043\n",
      "     0.6005955 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.732179\n",
      "     0.61328524]\n",
      "   [-0.5541568          nan         nan ...         nan  0.7321278\n",
      "     0.6133182 ]\n",
      "   [-0.54009897         nan         nan ...         nan  0.7320574\n",
      "     0.61336035]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.7152345\n",
      "     0.6016311 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.714475\n",
      "     0.60104716]\n",
      "   [-0.7118441          nan         nan ...         nan  0.71389043\n",
      "     0.6005955 ]]]\n",
      "\n",
      "\n",
      " [[[-0.83323246  0.07448032  0.21345653 ...         nan -0.14857219\n",
      "    -0.9150603 ]\n",
      "   [-0.83323246  0.0227643   0.13935159 ...         nan -0.14917468\n",
      "    -0.9151208 ]\n",
      "   [-0.780351   -0.04178777  0.04396283 ...         nan -0.14990702\n",
      "    -0.91520697]\n",
      "   ...\n",
      "   [-0.4953167  -0.39074808 -0.5672674  ...         nan -0.21001914\n",
      "    -0.90664333]\n",
      "   [-0.54009897 -0.39094827 -0.5457615  ...         nan -0.21174471\n",
      "    -0.9059914 ]\n",
      "   [-0.54009897 -0.4019963  -0.5312576  ...         nan -0.21313673\n",
      "    -0.9054749 ]]\n",
      "\n",
      "  [[-0.83323246  0.0606132   0.17894585 ...         nan -0.14718369\n",
      "    -0.9148634 ]\n",
      "   [-0.83323246  0.02132211  0.13527027 ...         nan -0.1478126\n",
      "    -0.91492337]\n",
      "   [-0.780351   -0.03320958  0.06897927 ...         nan -0.14857893\n",
      "    -0.9149983 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.41139022 -0.5686273  ...         nan -0.20838402\n",
      "    -0.90646636]\n",
      "   [-0.54009897 -0.40788296 -0.54664594 ...         nan -0.21011756\n",
      "    -0.9058051 ]\n",
      "   [-0.54009897 -0.41277748 -0.5325633  ...         nan -0.21146253\n",
      "    -0.9052879 ]]\n",
      "\n",
      "  [[-0.83323246  0.03555314  0.10885455 ...         nan -0.14478944\n",
      "    -0.9145197 ]\n",
      "   [-0.83323246  0.02015322  0.12132642 ...         nan -0.14546593\n",
      "    -0.9145759 ]\n",
      "   [-0.780351   -0.01624141  0.10796533 ...         nan -0.14628507\n",
      "    -0.91464335]\n",
      "   ...\n",
      "   [-0.4953167  -0.44061053 -0.56218195 ...         nan -0.2055305\n",
      "    -0.9061631 ]\n",
      "   [-0.54009897 -0.43211943 -0.5409507  ...         nan -0.20728098\n",
      "    -0.9054972 ]\n",
      "   [-0.54009897 -0.4246079  -0.5264298  ...         nan -0.20855626\n",
      "    -0.90496784]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.24671781 -0.2891531  ...         nan -0.210026\n",
      "    -0.898544  ]\n",
      "   [-0.5541568  -0.26463366 -0.28133518 ...         nan -0.20623852\n",
      "    -0.8985614 ]\n",
      "   [-0.54009897 -0.28582639 -0.28596947 ...         nan -0.20132355\n",
      "    -0.89859664]\n",
      "   ...\n",
      "   [-0.66202563 -0.25380662 -0.24927486 ...         nan  0.0390315\n",
      "    -0.8979821 ]\n",
      "   [-0.7118441  -0.22274792 -0.20200348 ...         nan  0.04001711\n",
      "    -0.8976308 ]\n",
      "   [-0.7118441  -0.19393688 -0.15517437 ...         nan  0.04078995\n",
      "    -0.8973481 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan -0.210026\n",
      "    -0.898544  ]\n",
      "   [-0.5541568          nan         nan ...         nan -0.20623852\n",
      "    -0.8985614 ]\n",
      "   [-0.54009897         nan         nan ...         nan -0.20132355\n",
      "    -0.89859664]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.0390315\n",
      "    -0.8979821 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.04001711\n",
      "    -0.8976308 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.04078995\n",
      "    -0.8973481 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan -0.210026\n",
      "    -0.898544  ]\n",
      "   [-0.5541568          nan         nan ...         nan -0.20623852\n",
      "    -0.8985614 ]\n",
      "   [-0.54009897         nan         nan ...         nan -0.20132355\n",
      "    -0.89859664]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.0390315\n",
      "    -0.8979821 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.04001711\n",
      "    -0.8976308 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.04078995\n",
      "    -0.8973481 ]]]\n",
      "\n",
      "\n",
      " [[[-0.83323246 -0.13330863 -0.1537424  ...         nan  0.24745722\n",
      "     0.6925871 ]\n",
      "   [-0.83323246 -0.1456944  -0.1379751  ...         nan  0.24722287\n",
      "     0.6919032 ]\n",
      "   [-0.780351   -0.1632939  -0.13704018 ...         nan  0.24692255\n",
      "     0.6910142 ]\n",
      "   ...\n",
      "   [-0.4953167  -0.5418485  -0.75293404 ...         nan  0.23148844\n",
      "     0.6377882 ]\n",
      "   [-0.54009897 -0.55964214 -0.8182888  ...         nan  0.23090562\n",
      "     0.63684285]\n",
      "   [-0.54009897 -0.58747846 -0.8809468  ...         nan  0.23044482\n",
      "     0.6361127 ]]\n",
      "\n",
      "  [[-0.83323246 -0.15196407 -0.17131433 ...         nan  0.24633566\n",
      "     0.6918653 ]\n",
      "   [-0.83323246 -0.15050787 -0.1503461  ...         nan  0.24610847\n",
      "     0.6911721 ]\n",
      "   [-0.780351   -0.15502244 -0.14255753 ...         nan  0.2458159\n",
      "     0.69027454]\n",
      "   ...\n",
      "   [-0.4953167  -0.5559078  -0.7532641  ...         nan  0.23099312\n",
      "     0.6372428 ]\n",
      "   [-0.54009897 -0.5893135  -0.8073156  ...         nan  0.23044318\n",
      "     0.63630164]\n",
      "   [-0.54009897 -0.6290257  -0.85676974 ...         nan  0.230012\n",
      "     0.6355762 ]]\n",
      "\n",
      "  [[-0.83323246 -0.18563034 -0.19974937 ...         nan  0.24441735\n",
      "     0.6906341 ]\n",
      "   [-0.83323246 -0.15360653 -0.17075258 ...         nan  0.24420209\n",
      "     0.68992436]\n",
      "   [-0.780351   -0.13432974 -0.15045348 ...         nan  0.24392167\n",
      "     0.68901175]\n",
      "   ...\n",
      "   [-0.4953167  -0.5665982  -0.73829883 ...         nan  0.23014973\n",
      "     0.6363158 ]\n",
      "   [-0.54009897 -0.63615894 -0.77124375 ...         nan  0.22965625\n",
      "     0.63538235]\n",
      "   [-0.54009897 -0.7030283  -0.8049834  ...         nan  0.22927585\n",
      "     0.6346642 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.5541568  -0.61916566 -0.62669677 ...         nan  0.22472647\n",
      "     0.6928904 ]\n",
      "   [-0.5541568  -0.6324384  -0.6368019  ...         nan  0.22442229\n",
      "     0.6916709 ]\n",
      "   [-0.54009897 -0.6261303  -0.61465156 ...         nan  0.2240314\n",
      "     0.690106  ]\n",
      "   ...\n",
      "   [-0.66202563 -0.2106646  -0.21280845 ...         nan  0.21293141\n",
      "     0.6131693 ]\n",
      "   [-0.7118441  -0.17420667 -0.16414247 ...         nan  0.21331108\n",
      "     0.61258656]\n",
      "   [-0.7118441  -0.1385895  -0.11500601 ...         nan  0.2136063\n",
      "     0.6121382 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.22472647\n",
      "     0.6928904 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.22442229\n",
      "     0.6916709 ]\n",
      "   [-0.54009897         nan         nan ...         nan  0.2240314\n",
      "     0.690106  ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.21293141\n",
      "     0.6131693 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.21331108\n",
      "     0.61258656]\n",
      "   [-0.7118441          nan         nan ...         nan  0.2136063\n",
      "     0.6121382 ]]\n",
      "\n",
      "  [[-0.5541568          nan         nan ...         nan  0.22472647\n",
      "     0.6928904 ]\n",
      "   [-0.5541568          nan         nan ...         nan  0.22442229\n",
      "     0.6916709 ]\n",
      "   [-0.54009897         nan         nan ...         nan  0.2240314\n",
      "     0.690106  ]\n",
      "   ...\n",
      "   [-0.66202563         nan         nan ...         nan  0.21149027\n",
      "     0.6131693 ]\n",
      "   [-0.7118441          nan         nan ...         nan  0.21331108\n",
      "     0.61258656]\n",
      "   [-0.7118441          nan         nan ...         nan  0.2136063\n",
      "     0.6121382 ]]]]\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to print the first record in the dataset\n",
    "def print_first_record(dataset, dataset_name=\"Dataset\"):\n",
    "    print(f\"--- First Record from {dataset_name} ---\")\n",
    "    for data, label in dataset.take(1):  # Take a single batch from the dataset\n",
    "        print(f\"Data: {data[0]}\")\n",
    "        print(f\"Label: {label[0]}\")\n",
    "\n",
    "# Print the first record for the train dataset\n",
    "print_first_record(train_dataset, \"Train Dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "def train_model(model, num_epochs=10):\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Custom learning rate scheduler\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    # Define the path where the best model will be saved\n",
    "    best_model_filepath = f\"{log_dir}/best_model.h5\"\n",
    "    \n",
    "    # ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        best_model_filepath,\n",
    "        monitor='val_accuracy',  # Change to monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "        mode='max',  # Change to 'max' for accuracy, since we want the highest value\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    callbacks_list = [\n",
    "        tensorboard_callback,\n",
    "        # LearningRateScheduler(custom_lr_scheduler, verbose=1),\n",
    "        checkpoint_callback  # Add ModelCheckpoint to callbacks\n",
    "    ]\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        # validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    # Load the best weights from the saved model\n",
    "    model.load_weights(best_model_filepath)\n",
    "\n",
    "    # Evaluate the best model on the training dataset\n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    \n",
    "    # Evaluate the best model on the validation dataset\n",
    "    val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "\n",
    "    # Print training and validation accuracy\n",
    "    print(f\"Best model training accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Best model validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    # Return the model with the best weights\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'lon', 'lat', 'soy_y_bu_per_m2', 'corn_y_bu_per_m2',\n",
      "       'soy_y_bu_per_patch', 'corn_y_bu_per_patch'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean up the column names to remove any hidden spaces or non-printing characters\n",
    "labels_df.columns = labels_df.columns.str.strip()\n",
    "\n",
    "# Now, you should be able to access 'corn_y_bu_per_m2' without any issues\n",
    "print(labels_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "\n",
    "def create_cnn_lstm_model(input_shape):\n",
    "    # Model definition\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # TimeDistributed wrapper applies a layer to every temporal slice of an input.\n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same'), input_shape=input_shape))\n",
    "    model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "    \n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same')))\n",
    "    model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "\n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(16, (3, 3), activation='relu', padding='same')))\n",
    "    model.add(layers.TimeDistributed(layers.MaxPooling2D((2, 2))))\n",
    "    \n",
    "    # Flatten the spatial dimensions, but keep the temporal dimension\n",
    "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "    \n",
    "    # LSTM layer to process the temporal sequence\n",
    "    model.add(layers.LSTM(256, return_sequences=False))\n",
    "    \n",
    "    # Dense layers for classification\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_7              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,704</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_7              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │         \u001b[38;5;34m8,704\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_8              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m4,624\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,311,744\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,606,705</span> (6.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,606,705\u001b[0m (6.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,606,705</span> (6.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,606,705\u001b[0m (6.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_cnn_lstm = create_cnn_lstm_model(timeseries_shape)\n",
    "\n",
    "model_cnn_lstm.compile(\n",
    "    optimizer=\"adam\", loss=MeanAbsoluteError(), metrics=[MeanAbsoluteError()]\n",
    ")\n",
    "\n",
    "model_cnn_lstm.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_lstm = train_model(model_cnn_lstm, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset contains 20 batches.\n"
     ]
    }
   ],
   "source": [
    "# Check the number of batches in the test dataset\n",
    "dataset_length = sum(1 for _ in test_dataset)\n",
    "print(f\"Test dataset contains {dataset_length} batches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "# If the dataset only contains features and no labels for test data\n",
    "# Predict on the test dataset and do not evaluate accuracy\n",
    "predictions = model_cnn_lstm.predict(test_dataset)\n",
    "\n",
    "# If predictions are in a NumPy array, convert it to a Pandas DataFrame\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "\n",
    "# Save the predictions to an Excel file (make sure to use the correct file path)\n",
    "predictions_df.to_excel('predictions.xlsx', index=False, header=False)  # Adjust 'header' as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model_cnn_lstm.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "[0.33050215 0.13389957 0.13389957 0.13389957 0.13389957 0.13389957]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "predictions = model_cnn_lstm.predict(test_dataset)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model_cnn_lstm.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
