{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size_pixels = 64\n",
    "model_input_width = 6  # number of images before the event\n",
    "buffer_size = 100\n",
    "# num_classes = 6\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "datasets_folder = os.path.join(\"E:\\\\Workspace\\\\Thesis_dataset\", \"illinois_dataset\")\n",
    "# dataset_folder_name = \"Quercus_germany_200_stations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test_data.npz\n",
      "E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test.csv\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_folder_path = datasets_folder\n",
    "os.makedirs(dataset_folder_path, exist_ok=True)\n",
    "\n",
    "record_id_column_name = 'record_id'\n",
    "label_column_name = \"val_yield\"\n",
    "\n",
    "train_timeseries_file_path = os.path.join(dataset_folder_path, \"test_data.npz\")\n",
    "print(train_timeseries_file_path)\n",
    "train_label_file_path = os.path.join(dataset_folder_path, \"test.csv\")\n",
    "print(train_label_file_path)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 64, 64, 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_file = np.load(train_timeseries_file_path, mmap_mode=\"r\")\n",
    "first_array_key = next(iter(npz_file))\n",
    "timeseries_shape = npz_file[first_array_key].shape\n",
    "timeseries_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train.csv\"\n",
    "test_label_file_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\test.csv\"\n",
    "record_id_column_name = \"id\"\n",
    "label_column_name = \"val_yield\"\n",
    "timeseries_npz_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train_data.npz\"\n",
    "test_timeseries_file_path = r\"E:\\Workspace\\Thesis_dataset\\illinois_dataset\\train_data.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    label_csv_path, record_id_column_name, label_column_name, timeseries_npz_path\n",
    "):\n",
    "\n",
    "    # Check if the inputs are a byte string and decode it to a regular string if necessary\n",
    "    if isinstance(label_csv_path, bytes):\n",
    "        label_csv_path = label_csv_path.decode(\"utf-8\")\n",
    "    if isinstance(timeseries_npz_path, bytes):\n",
    "        timeseries_npz_path = timeseries_npz_path.decode(\"utf-8\")\n",
    "    if isinstance(record_id_column_name, bytes):\n",
    "        record_id_column_name = record_id_column_name.decode(\"utf-8\")\n",
    "    if isinstance(label_column_name, bytes):\n",
    "        label_column_name = label_column_name.decode(\"utf-8\")\n",
    "\n",
    "    # Load the labels CSV\n",
    "    labels_df = pd.read_csv(label_csv_path)\n",
    "\n",
    "    # Load the npz file\n",
    "    with np.load(timeseries_npz_path, allow_pickle=True) as npz_file:\n",
    "        for _, row in labels_df.iterrows():\n",
    "            record_id = str(\n",
    "                row[record_id_column_name]\n",
    "            )  # Ensure record_id is treated as a string\n",
    "            target = row[label_column_name]\n",
    "            if record_id in npz_file.files:\n",
    "                # Extract the time series data using record_id\n",
    "                time_series = npz_file[record_id]\n",
    "                # print(record_id, target)\n",
    "                yield time_series, target\n",
    "\n",
    "\n",
    "# Determine the output types\n",
    "output_types = (tf.float32, tf.int64)\n",
    "\n",
    "# Determine the output shapes\n",
    "output_shapes = (timeseries_shape, ())  #  ((6, 11, 64, 64), ())\n",
    "\n",
    "# Create train dataset\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,  # Generator function\n",
    "    args=(\n",
    "        train_label_file_path,\n",
    "        record_id_column_name,\n",
    "        label_column_name,\n",
    "        train_timeseries_file_path,\n",
    "    ),  # Arguments to pass to the generator\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes,\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=buffer_size)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,  # Generator function\n",
    "    args=(\n",
    "        test_label_file_path,\n",
    "        record_id_column_name,\n",
    "        label_column_name,\n",
    "        test_timeseries_file_path,\n",
    "    ),  # Arguments to pass to the generator\n",
    "    output_types=output_types,\n",
    "    output_shapes=output_shapes,\n",
    ")\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train Dataset ---\n",
      "Shape of data: (8, 6, 64, 64, 15)\n",
      "Shape of label: (8,)\n",
      "--- Test Dataset ---\n",
      "Shape of data: (8, 6, 64, 64, 15)\n",
      "Shape of label: (8,)\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_shapes(dataset, dataset_name=\"Dataset\"):\n",
    "    print(f\"--- {dataset_name} ---\")\n",
    "    for batch in dataset.take(1):  # Take a single batch from the dataset\n",
    "        data, label = batch  # Unpack the batch (time_series, target)\n",
    "        print(f\"Shape of data: {data.shape}\")\n",
    "        print(f\"Shape of label: {label.shape}\")\n",
    "# Print shapes for train, validation, and test datasets\n",
    "print_dataset_shapes(train_dataset, \"Train Dataset\")\n",
    "print_dataset_shapes(test_dataset, \"Test Dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First Record from Train Dataset ---\n",
      "Data: [[[[ 5.0000000e+00  1.2860000e+03  1.7970000e+03 ... -1.6407200e+01\n",
      "     3.4343082e+01  2.2865410e+01]\n",
      "   [ 5.0000000e+00  1.5090000e+03  2.0270000e+03 ... -1.7137825e+01\n",
      "     3.4349812e+01  2.2864410e+01]\n",
      "   [ 5.0000000e+00  1.7120000e+03  2.2330000e+03 ... -1.7570967e+01\n",
      "     3.4358711e+01  2.2863091e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  3.5900000e+02  7.5200000e+02 ... -1.8154581e+01\n",
      "     3.4569382e+01  2.2610416e+01]\n",
      "   [ 0.0000000e+00  3.6900000e+02  7.6200000e+02 ... -1.5714471e+01\n",
      "     3.4572651e+01  2.2605965e+01]\n",
      "   [ 0.0000000e+00  3.8400000e+02  7.7700000e+02 ... -1.3655651e+01\n",
      "     3.4575119e+01  2.2602600e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  1.0910000e+03  1.5730000e+03 ... -1.6018251e+01\n",
      "     3.4352974e+01  2.2866713e+01]\n",
      "   [ 5.0000000e+00  1.1890000e+03  1.6510000e+03 ... -1.7177349e+01\n",
      "     3.4359638e+01  2.2865726e+01]\n",
      "   [ 5.0000000e+00  1.3260000e+03  1.7800000e+03 ... -1.8147036e+01\n",
      "     3.4368458e+01  2.2864424e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  3.8200000e+02  7.7300000e+02 ... -1.9042477e+01\n",
      "     3.4573273e+01  2.2610910e+01]\n",
      "   [ 0.0000000e+00  3.8600000e+02  7.7700000e+02 ... -1.7223757e+01\n",
      "     3.4576378e+01  2.2606407e+01]\n",
      "   [ 0.0000000e+00  3.9400000e+02  7.8500000e+02 ... -1.5400288e+01\n",
      "     3.4578724e+01  2.2603003e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  7.5800000e+02  1.1920000e+03 ... -1.5354191e+01\n",
      "     3.4369865e+01  2.2868937e+01]\n",
      "   [ 5.0000000e+00  6.4100000e+02  1.0100000e+03 ... -1.7244829e+01\n",
      "     3.4376423e+01  2.2867973e+01]\n",
      "   [ 5.0000000e+00  6.6800000e+02  1.0050000e+03 ... -1.9130569e+01\n",
      "     3.4385098e+01  2.2866699e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.2000000e+02  8.0900000e+02 ... -2.0558399e+01\n",
      "     3.4579922e+01  2.2611753e+01]\n",
      "   [ 0.0000000e+00  4.1500000e+02  8.0300000e+02 ... -1.9800589e+01\n",
      "     3.4582745e+01  2.2607161e+01]\n",
      "   [ 0.0000000e+00  4.1100000e+02  7.9800000e+02 ... -1.8378937e+01\n",
      "     3.4584877e+01  2.2603689e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  7.3300000e+02  9.9200000e+02 ... -1.3377698e+01\n",
      "     3.4708683e+01  2.2782768e+01]\n",
      "   [ 5.0000000e+00  8.7100000e+02  1.1360000e+03 ... -1.3791551e+01\n",
      "     3.4720013e+01  2.2783272e+01]\n",
      "   [ 5.0000000e+00  1.0160000e+03  1.2880000e+03 ... -1.3913621e+01\n",
      "     3.4735004e+01  2.2783939e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  2.5900000e+02  5.4900000e+02 ... -1.6550804e+01\n",
      "     3.5660057e+01  2.2813551e+01]\n",
      "   [ 0.0000000e+00  3.8500000e+02  6.9800000e+02 ... -1.9247486e+01\n",
      "     3.5675819e+01  2.2814032e+01]\n",
      "   [ 0.0000000e+00  5.0400000e+02  8.3100000e+02 ... -2.1772902e+01\n",
      "     3.5687733e+01  2.2814396e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4708683e+01  2.2782768e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4720013e+01  2.2783272e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4735004e+01  2.2783939e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5660057e+01  2.2813551e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5675819e+01  2.2814032e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5687733e+01  2.2814396e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4708683e+01  2.2782768e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4720013e+01  2.2783272e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4735004e+01  2.2783939e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5660057e+01  2.2813551e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5675819e+01  2.2814032e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5687733e+01  2.2814396e+01]]]\n",
      "\n",
      "\n",
      " [[[ 5.0000000e+00  7.9400000e+02  9.6200000e+02 ... -1.6407200e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  8.3300000e+02  1.0130000e+03 ... -1.7137825e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  8.7100000e+02  1.0630000e+03 ... -1.7570967e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  6.1100000e+02  9.0100000e+02 ... -1.8154581e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.0300000e+02  8.6900000e+02 ... -1.5714471e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  5.9600000e+02  8.3500000e+02 ... -1.3655651e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  7.1700000e+02  8.9200000e+02 ... -1.6018251e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  7.4900000e+02  9.2800000e+02 ... -1.7177349e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  7.9600000e+02  9.8300000e+02 ... -1.8147036e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  6.2700000e+02  9.1400000e+02 ... -1.9042477e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.1800000e+02  8.9000000e+02 ... -1.7223757e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.0800000e+02  8.6600000e+02 ... -1.5400288e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  5.8700000e+02  7.7200000e+02 ... -1.5354191e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  6.0600000e+02  7.8500000e+02 ... -1.7244829e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  6.6900000e+02  8.4700000e+02 ... -1.9130569e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  6.5400000e+02  9.3500000e+02 ... -2.0558399e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.4300000e+02  9.2600000e+02 ... -1.9800589e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.3000000e+02  9.1800000e+02 ... -1.8378937e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  1.1500000e+03  1.2930000e+03 ... -1.3377698e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.3670000e+03  1.5030000e+03 ... -1.3791551e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.5450000e+03  1.6650000e+03 ... -1.3913621e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  5.7500000e+02  7.8100000e+02 ... -1.6550804e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.7300000e+02  9.0000000e+02 ... -1.9247486e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  7.5200000e+02  9.9400000e+02 ... -2.1772902e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[ 5.0000000e+00  8.9800000e+02  1.2920000e+03 ... -1.6407200e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0680000e+03  1.5050000e+03 ... -1.7137825e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.2440000e+03  1.7180000e+03 ... -1.7570967e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  2.5600000e+02  3.4300000e+02 ... -1.8154581e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.5400000e+02  3.5200000e+02 ... -1.5714471e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.5400000e+02  3.6900000e+02 ... -1.3655651e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  7.8700000e+02  1.1560000e+03 ... -1.6018251e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  8.8100000e+02  1.2710000e+03 ... -1.7177349e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0250000e+03  1.4450000e+03 ... -1.8147036e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  2.7100000e+02  3.7500000e+02 ... -1.9042477e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.5700000e+02  3.5500000e+02 ... -1.7223757e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.5100000e+02  3.5500000e+02 ... -1.5400288e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  5.9700000e+02  9.2300000e+02 ... -1.5354191e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  5.6200000e+02  8.7200000e+02 ... -1.7244829e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  6.5300000e+02  9.8000000e+02 ... -1.9130569e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  2.9700000e+02  4.3100000e+02 ... -2.0558399e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.6200000e+02  3.6200000e+02 ... -1.9800589e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  2.4700000e+02  3.3200000e+02 ... -1.8378937e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  7.1300000e+02  9.6000000e+02 ... -1.3377698e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  9.2700000e+02  1.1900000e+03 ... -1.3791551e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.1450000e+03  1.4190000e+03 ... -1.3913621e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.5000000e+02  7.4000000e+02 ... -1.6550804e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  5.5200000e+02  8.5500000e+02 ... -1.9247486e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  6.3200000e+02  9.3700000e+02 ... -2.1772902e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[ 5.0000000e+00  1.0346000e+04  9.4280000e+03 ... -1.6407200e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0346000e+04  9.4440000e+03 ... -1.7137825e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0350000e+04  9.4590000e+03 ... -1.7570967e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  1.0550000e+04  9.6280000e+03 ... -1.8154581e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0543000e+04  9.6380000e+03 ... -1.5714471e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0532000e+04  9.6420000e+03 ... -1.3655651e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  1.0333000e+04  9.4310000e+03 ... -1.6018251e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0338000e+04  9.4460000e+03 ... -1.7177349e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0346000e+04  9.4580000e+03 ... -1.8147036e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  1.0554000e+04  9.6060000e+03 ... -1.9042477e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0542000e+04  9.6200000e+03 ... -1.7223757e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0524000e+04  9.6290000e+03 ... -1.5400288e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00  1.0311000e+04  9.4370000e+03 ... -1.5354191e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0325000e+04  9.4490000e+03 ... -1.7244829e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0339000e+04  9.4570000e+03 ... -1.9130569e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  1.0561000e+04  9.5700000e+03 ... -2.0558399e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0539000e+04  9.5900000e+03 ... -1.9800589e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0509000e+04  9.6070000e+03 ... -1.8378937e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  1.0418000e+04  9.5450000e+03 ... -1.3377698e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0435000e+04  9.5580000e+03 ... -1.3791551e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00  1.0450000e+04  9.5690000e+03 ... -1.3913621e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00  1.0467000e+04  9.5470000e+03 ... -1.6550804e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0464000e+04  9.5440000e+03 ... -1.9247486e+01\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00  1.0458000e+04  9.5470000e+03 ... -2.1772902e+01\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     0.0000000e+00  0.0000000e+00]]]\n",
      "\n",
      "\n",
      " [[[ 5.0000000e+00  7.1200000e+02  9.6800000e+02 ... -1.6407200e+01\n",
      "     3.3837791e+01  2.4061111e+01]\n",
      "   [ 5.0000000e+00  7.5700000e+02  1.0620000e+03 ... -1.7137825e+01\n",
      "     3.3838188e+01  2.4061111e+01]\n",
      "   [ 5.0000000e+00  8.0500000e+02  1.1660000e+03 ... -1.7570967e+01\n",
      "     3.3838711e+01  2.4061111e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.5400000e+02  7.8600000e+02 ... -1.8154581e+01\n",
      "     3.2752529e+01  2.4122358e+01]\n",
      "   [ 0.0000000e+00  4.4800000e+02  7.8300000e+02 ... -1.5714471e+01\n",
      "     3.2733040e+01  2.4123457e+01]\n",
      "   [ 0.0000000e+00  4.4100000e+02  7.8700000e+02 ... -1.3655651e+01\n",
      "     3.2718311e+01  2.4124287e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  6.5900000e+02  9.3100000e+02 ... -1.6018251e+01\n",
      "     3.3834896e+01  2.4060490e+01]\n",
      "   [ 5.0000000e+00  7.5200000e+02  1.0660000e+03 ... -1.7177349e+01\n",
      "     3.3835140e+01  2.4060490e+01]\n",
      "   [ 5.0000000e+00  8.6900000e+02  1.2280000e+03 ... -1.8147036e+01\n",
      "     3.3835464e+01  2.4060490e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.6100000e+02  7.8900000e+02 ... -1.9042477e+01\n",
      "     3.2749100e+01  2.4121826e+01]\n",
      "   [ 0.0000000e+00  4.5600000e+02  7.8800000e+02 ... -1.7223757e+01\n",
      "     3.2729404e+01  2.4122938e+01]\n",
      "   [ 0.0000000e+00  4.5000000e+02  7.9200000e+02 ... -1.5400288e+01\n",
      "     3.2714516e+01  2.4123777e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  5.7000000e+02  8.6700000e+02 ... -1.5354191e+01\n",
      "     3.3829948e+01  2.4059429e+01]\n",
      "   [ 5.0000000e+00  7.4300000e+02  1.0710000e+03 ... -1.7244829e+01\n",
      "     3.3829937e+01  2.4059429e+01]\n",
      "   [ 5.0000000e+00  9.7900000e+02  1.3340000e+03 ... -1.9130569e+01\n",
      "     3.3829922e+01  2.4059429e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.7200000e+02  7.9400000e+02 ... -2.0558399e+01\n",
      "     3.2743248e+01  2.4120916e+01]\n",
      "   [ 0.0000000e+00  4.6900000e+02  7.9700000e+02 ... -1.9800589e+01\n",
      "     3.2723194e+01  2.4122051e+01]\n",
      "   [ 0.0000000e+00  4.6500000e+02  8.0000000e+02 ... -1.8378937e+01\n",
      "     3.2708038e+01  2.4122910e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  8.3200000e+02  1.1140000e+03 ... -1.3377698e+01\n",
      "     3.4783623e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00  9.7300000e+02  1.2610000e+03 ... -1.3791551e+01\n",
      "     3.4800064e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00  1.1260000e+03  1.4180000e+03 ... -1.3913621e+01\n",
      "     3.4821819e+01  2.4049999e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  3.7400000e+02  6.4900000e+02 ... -1.6550804e+01\n",
      "     3.5366261e+01  2.4065704e+01]\n",
      "   [ 0.0000000e+00  4.6200000e+02  7.6900000e+02 ... -1.9247486e+01\n",
      "     3.5373970e+01  2.4066004e+01]\n",
      "   [ 0.0000000e+00  5.3900000e+02  8.6700000e+02 ... -2.1772902e+01\n",
      "     3.5379799e+01  2.4066229e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4783623e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4800064e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4821819e+01  2.4049999e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5366261e+01  2.4065704e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5373970e+01  2.4066004e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5379799e+01  2.4066229e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4783623e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4800064e+01  2.4049999e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     3.4821819e+01  2.4049999e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5366261e+01  2.4065704e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5373970e+01  2.4066004e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.5379799e+01  2.4066229e+01]]]\n",
      "\n",
      "\n",
      " [[[ 5.0000000e+00  3.1700000e+03  3.1640000e+03 ... -1.6407200e+01\n",
      "     3.0057882e+01  1.8156919e+01]\n",
      "   [ 5.0000000e+00  3.2980000e+03  3.3230000e+03 ... -1.7137825e+01\n",
      "     3.0063480e+01  1.8157221e+01]\n",
      "   [ 5.0000000e+00  3.5010000e+03  3.5470000e+03 ... -1.7570967e+01\n",
      "     3.0070885e+01  1.8157619e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.1600000e+02  7.0400000e+02 ... -1.8154581e+01\n",
      "     3.0116011e+01  1.8104601e+01]\n",
      "   [ 0.0000000e+00  4.0800000e+02  7.0000000e+02 ... -1.5714471e+01\n",
      "     3.0116398e+01  1.8103628e+01]\n",
      "   [ 0.0000000e+00  4.0200000e+02  7.0500000e+02 ... -1.3655651e+01\n",
      "     3.0116690e+01  1.8102894e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  3.0550000e+03  3.0110000e+03 ... -1.6018251e+01\n",
      "     3.0062101e+01  1.8157324e+01]\n",
      "   [ 5.0000000e+00  3.1610000e+03  3.1120000e+03 ... -1.7177349e+01\n",
      "     3.0067699e+01  1.8157621e+01]\n",
      "   [ 5.0000000e+00  3.3270000e+03  3.2670000e+03 ... -1.8147036e+01\n",
      "     3.0075104e+01  1.8158018e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.2100000e+02  7.1000000e+02 ... -1.9042477e+01\n",
      "     3.0121281e+01  1.8104683e+01]\n",
      "   [ 0.0000000e+00  4.1400000e+02  7.0800000e+02 ... -1.7223757e+01\n",
      "     3.0121609e+01  1.8103689e+01]\n",
      "   [ 0.0000000e+00  4.0900000e+02  7.1300000e+02 ... -1.5400288e+01\n",
      "     3.0121857e+01  1.8102938e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00  2.8590000e+03  2.7490000e+03 ... -1.5354191e+01\n",
      "     3.0069305e+01  1.8158012e+01]\n",
      "   [ 5.0000000e+00  2.9260000e+03  2.7510000e+03 ... -1.7244829e+01\n",
      "     3.0074902e+01  1.8158308e+01]\n",
      "   [ 5.0000000e+00  3.0310000e+03  2.7900000e+03 ... -1.9130569e+01\n",
      "     3.0082308e+01  1.8158697e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  4.2900000e+02  7.2100000e+02 ... -2.0558399e+01\n",
      "     3.0130280e+01  1.8104822e+01]\n",
      "   [ 0.0000000e+00  4.2500000e+02  7.2200000e+02 ... -1.9800589e+01\n",
      "     3.0130505e+01  1.8103792e+01]\n",
      "   [ 0.0000000e+00  4.2200000e+02  7.2700000e+02 ... -1.8378937e+01\n",
      "     3.0130676e+01  1.8103014e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 5.0000000e+00  7.3100000e+02  9.5600000e+02 ... -1.3377698e+01\n",
      "     2.9604723e+01  1.8184834e+01]\n",
      "   [ 5.0000000e+00  8.6800000e+02  1.1010000e+03 ... -1.3791551e+01\n",
      "     2.9620523e+01  1.8184893e+01]\n",
      "   [ 5.0000000e+00  1.0140000e+03  1.2530000e+03 ... -1.3913621e+01\n",
      "     2.9641428e+01  1.8184969e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00  3.7200000e+02  6.1300000e+02 ... -1.6550804e+01\n",
      "     3.0400032e+01  1.8187471e+01]\n",
      "   [ 0.0000000e+00  4.4100000e+02  7.2300000e+02 ... -1.9247486e+01\n",
      "     3.0411915e+01  1.8187510e+01]\n",
      "   [ 0.0000000e+00  4.9900000e+02  8.1500000e+02 ... -2.1772902e+01\n",
      "     3.0420897e+01  1.8187538e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9604723e+01  1.8184834e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9620523e+01  1.8184893e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9641428e+01  1.8184969e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0400032e+01  1.8187471e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0411915e+01  1.8187510e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0420897e+01  1.8187538e+01]]\n",
      "\n",
      "  [[ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9604723e+01  1.8184834e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9620523e+01  1.8184893e+01]\n",
      "   [ 5.0000000e+00            nan            nan ...            nan\n",
      "     2.9641428e+01  1.8184969e+01]\n",
      "   ...\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0400032e+01  1.8187471e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0411915e+01  1.8187510e+01]\n",
      "   [ 0.0000000e+00            nan            nan ...            nan\n",
      "     3.0420897e+01  1.8187538e+01]]]]\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Function to print the first record in the dataset\n",
    "def print_first_record(dataset, dataset_name=\"Dataset\"):\n",
    "    print(f\"--- First Record from {dataset_name} ---\")\n",
    "    for data, label in dataset.take(1):  # Take a single batch from the dataset\n",
    "        print(f\"Data: {data[0]}\")\n",
    "\n",
    "# Print the first record for the train dataset\n",
    "print_first_record(train_dataset, \"Train Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "def train_model(model, train_dataset,  num_epochs=10):\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Custom learning rate scheduler\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "\n",
    "    # Define the path where the best model will be saved\n",
    "    best_model_filepath = f\"{log_dir}/best_model.h5\"\n",
    "    \n",
    "    # ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        best_model_filepath,\n",
    "        monitor='loss',  # Change to monitor validation accuracy\n",
    "        save_best_only=True,\n",
    "        mode='min',  # Change to 'max' for accuracy, since we want the highest value\n",
    "        verbose=1\n",
    "    )\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    callbacks_list = [\n",
    "        tensorboard_callback,\n",
    "        # LearningRateScheduler(custom_lr_scheduler, verbose=1),\n",
    "        checkpoint_callback  # Add ModelCheckpoint to callbacks\n",
    "    ]\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks_list,\n",
    "        # validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    # Load the best weights from the saved model\n",
    "    model.load_weights(best_model_filepath)\n",
    "\n",
    "    # Evaluate the best model on the training dataset\n",
    "    train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
    "    \n",
    "    # Evaluate the best model on the validation dataset\n",
    "    # val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
    "\n",
    "    # Print training and validation accuracy\n",
    "    print(f\"Best model training accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Best model validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    # Return the model with the best weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_25      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_307 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">246,016</span> │ reshape_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ dense_307[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_307[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_307[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_308 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_25      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m15\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ input_layer_25[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m960\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_307 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │    \u001b[38;5;34m246,016\u001b[0m │ reshape_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ dense_307[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_307[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_59 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_307[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_60 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_61 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_62 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_308 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │        \u001b[38;5;34m257\u001b[0m │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,455,937</span> (17.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,455,937\u001b[0m (17.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,455,937</span> (17.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,455,937\u001b[0m (17.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# VIT #\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_vit_regression(img_size, patch_size, d_model, num_frames, num_layers, num_outputs):\n",
    "    num_patches = (img_size[0] // patch_size) * (img_size[1] // patch_size)  # Number of patches per frame\n",
    "    sequence_length = num_frames * num_patches  # Total number of patches (tokens)\n",
    "\n",
    "    # Define input shape to match the 15 channels\n",
    "    inputs = layers.Input(shape=(num_frames, img_size[0], img_size[1], 15))  # (batch_size, num_frames, height, width, channels)\n",
    "\n",
    "    # Flatten spatial dimensions into patches\n",
    "    x = layers.Reshape((num_frames, num_patches, patch_size * patch_size * 15))(inputs)  # Flatten into patches of size patch_size*patch_size*15\n",
    "\n",
    "    # Add Linear Projection to d_model dimension\n",
    "    x = layers.Dense(d_model)(x)  # Project each patch to the d_model dimension\n",
    "    \n",
    "    # Add transformer layers\n",
    "    for _ in range(num_layers):\n",
    "        # Add Multi-Head Attention\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=d_model)(x, x)\n",
    "        attention_output = layers.LayerNormalization(epsilon=1e-6)(attention_output + x)  # Add residual connection\n",
    "        x = attention_output\n",
    "    \n",
    "    # Output layer (regression)\n",
    "    outputs = layers.Dense(num_outputs)(x)  # Output a single value for regression\n",
    "    \n",
    "    # Create the model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Model Parameters\n",
    "img_size = (64, 64)  # Image size (64x64)\n",
    "patch_size = 8  # Patch size (8x8)\n",
    "d_model = 256  # Dimension of model (output of linear projection)\n",
    "num_frames = 6  # Number of frames in the input sequence\n",
    "num_layers = 4  # Number of transformer layers\n",
    "num_outputs = 1  # Output for regression (e.g., crop yield)\n",
    "\n",
    "# Create the ViT regression model\n",
    "model = create_vit_regression(\n",
    "    img_size=img_size,\n",
    "    patch_size=patch_size,\n",
    "    d_model=d_model,\n",
    "    num_frames=num_frames,\n",
    "    num_layers=num_layers,\n",
    "    num_outputs=num_outputs\n",
    ")\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vit_model(model, train_dataset, num_epochs=10):\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    # Custom learning rate scheduler\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=0.0001,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    best_model_filepath = f\"{log_dir}/best_model.h5\"\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        best_model_filepath,\n",
    "        monitor='loss',  \n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    callbacks_list = [\n",
    "        tensorboard_callback,\n",
    "        checkpoint_callback  \n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks_list,\n",
    "    )\n",
    "\n",
    "    model.load_weights(best_model_filepath)\n",
    "\n",
    "    train_loss = model.evaluate(train_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Best model training loss: {train_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_311 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">246,016</span> │ reshape_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ dense_311[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_311[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dense_311[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,051,904</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ add_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_312 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_27      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m15\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ input_layer_27[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m960\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_311 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │    \u001b[38;5;34m246,016\u001b[0m │ reshape_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ dense_311[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_311[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_67 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ dense_311[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_68 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_69 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │  \u001b[38;5;34m1,051,904\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_70 (\u001b[38;5;33mAdd\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)              │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │        \u001b[38;5;34m512\u001b[0m │ add_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │ \u001b[38;5;34m256\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_312 (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)  │        \u001b[38;5;34m257\u001b[0m │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,455,937</span> (17.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,455,937\u001b[0m (17.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,455,937</span> (17.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,455,937\u001b[0m (17.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      6/Unknown \u001b[1m6s\u001b[0m 355ms/step - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: loss did not improve from inf\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 429ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: loss did not improve from inf\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 453ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: loss did not improve from inf\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 449ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: loss did not improve from inf\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 466ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m2/6\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 394ms/step - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Now you can train the model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrain_vit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[125], line 34\u001b[0m, in \u001b[0;36mtrain_vit_model\u001b[1;34m(model, train_dataset, num_epochs)\u001b[0m\n\u001b[0;32m     28\u001b[0m callbacks_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     29\u001b[0m     tensorboard_callback,\n\u001b[0;32m     30\u001b[0m     checkpoint_callback  \u001b[38;5;66;03m# Add ModelCheckpoint to callbacks\u001b[39;00m\n\u001b[0;32m     31\u001b[0m ]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Load the best weights from the saved model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(best_model_filepath)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Surya Naganathan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model Parameters\n",
    "img_size = (64, 64)  \n",
    "patch_size = 8 \n",
    "d_model = 256  \n",
    "num_frames = 6  \n",
    "num_layers = 4  \n",
    "num_outputs = 1  \n",
    "\n",
    "# Create the ViT regression model\n",
    "model = create_vit_regression(\n",
    "    img_size=img_size,\n",
    "    patch_size=patch_size,\n",
    "    d_model=d_model,\n",
    "    num_frames=num_frames,\n",
    "    num_layers=num_layers,\n",
    "    num_outputs=num_outputs\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "train_vit_model(model, train_dataset, num_epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
